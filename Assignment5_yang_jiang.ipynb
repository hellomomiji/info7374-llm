{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKwp7sSzdSlTiwPRdzrla6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hellomomiji/info7374-llm/blob/main/Assignment5_yang_jiang.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agents are an emerging field thats use reflection, tools, planning, and multi agent collaboration\n",
        "\n",
        "In this assignment, we will build a research agent. We will use serverless LLM endpoints. To get started, you create an account with Together AI or Anthropic. They should provide you with a few dollars worth of credits that should be enough to complete the assignment. You are free to choose any other provider such as OpenAI, Mistral, Fireworks, or Groq. I encourage you to play around with different models to get a feel for how they work. For this assignment, the API usage cost should be around a couple dollars. Depending on the model you choose and how many attempts you use, it may be a couple cents. For OpenAI, Anthropic, and Mistral, double check what model you are using. The flagship models are significantly more expensive than the smaller models (pricing between models varies by 50x). For the purposes of this assignment, it is sufficient to use the smallest/cheapest models.\n",
        "\n",
        "TogetherAI, Fireworks, and Groq run open source models. For these, it’s better to run the mid-large tier models. Mixtral is a good place to start. It’s good to play around with different models.\n",
        "\n",
        "Many providers are able to use OpenAI's client library, but some do not (like Anthropic). Use whatever makes sense.\n",
        "\n",
        "You can run this on Colab with a CPU, or locally and submit the Jupyter notebook as your submission. Since we are using third party providers for the LLMs, we will not load the model locally. If you run on Colab, take special care to not leak your API key. Here’s an example of how to properly use secrets in Colab.\n",
        "\n",
        "Research Agent\n",
        "Build an LLM-based research agent that can take a research topic, find relevant information, and generate a short summary (~1 paragraph) on the given topic.\n",
        "\n"
      ],
      "metadata": {
        "id": "PtjNs2P9k-Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install together"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr9q60vUlgFE",
        "outputId": "cb14fc30-0559-457b-f206-35e4517dc12f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: together in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.10/dist-packages (from together) (3.11.9)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from together) (8.1.7)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from together) (0.2.0)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.10/dist-packages (from together) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from together) (1.26.4)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from together) (10.4.0)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from together) (17.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from together) (2.10.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.10/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.10/dist-packages (from together) (4.66.6)\n",
            "Requirement already satisfied: typer<0.14,>=0.9 in /usr/local/lib/python3.10/dist-packages (from together) (0.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.18.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.14,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from together import Together\n",
        "import openai\n",
        "\n",
        "togetherai_api_key = userdata.get('togetherai')\n",
        "\n",
        "client = Together(api_key=togetherai_api_key)\n",
        "\n",
        "# client = openai.OpenAI(\n",
        "#     api_key=togetherai_api_key,\n",
        "#     base_url=\"https://api.together.xyz/v1\"\n",
        "# )"
      ],
      "metadata": {
        "id": "oMI2Em6jlP4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Client wrapper\n",
        "def get_response(model, sys_prompt, user_prompt):\n",
        "  response = client.chat.completions.create(\n",
        "      model=model,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"system\",\n",
        "              \"content\": sys_prompt\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": user_prompt\n",
        "          }\n",
        "      ],\n",
        "      max_tokens=512,\n",
        "      stop=None,\n",
        "      temperature=0.7\n",
        "  )\n",
        "  return response\n"
      ],
      "metadata": {
        "id": "niX6x-JPd8zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools to Implement (20 points, 4 points each):\n",
        "\n"
      ],
      "metadata": {
        "id": "9hXF16ghckiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Topic Breakdown Tool: Create a tool that takes a broad research topic and breaks it down into smaller, more focused subtopics or subqueries. You can use an LLM to generate these subtopics based on the main topic.\n"
      ],
      "metadata": {
        "id": "GV_fW0QpctD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Topic Breakdown Tool\n",
        "\n",
        "model = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "topic_breakdown_sys = \"You are an research assistant doing a research on AI and Machine Learning.\"\n",
        "topic_breakdown_user = \"Generate five consice and more focused subtopics for this research topic: {topic}.\"\n",
        "\n",
        "def topic_breakdown(topic):\n",
        "  response = get_response(\n",
        "      model=model,\n",
        "      sys_prompt=topic_breakdown_sys,\n",
        "      user_prompt=f\"{topic_breakdown_user.format(topic=topic)}\"\n",
        "  )\n",
        "\n",
        "  subtopics = response.choices[0].message.content\n",
        "  return subtopics"
      ],
      "metadata": {
        "id": "tem8pDvpcJcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# topic_breakdown(\"LLM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "8_NpgIKQhvJr",
        "outputId": "483fda22-b340-4b01-e705-2bb907f7fac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 1. Development and analysis of language modeling techniques in LLM: This subtopic will focus on the exploration of various language modeling methods, their applications, and comparative analysis to improve the efficiency and effectiveness of language generation in LLM.\\n\\n2. Advancements in LLM training strategies: This subtopic will delve into the latest strategies for training large language models, including data selection, preprocessing, and optimization techniques, with a focus on reducing training time and improving model performance.\\n\\n3. Evaluation and benchmarking of LLM performance: This subtopic will focus on the development and implementation of suitable evaluation metrics and benchmark datasets to assess the performance of large language models in various aspects such as fluency, accuracy, and generalization.\\n\\n4. Exploring applications of LLM in real-world scenarios: This subtopic will examine the practical applications of large language models in areas like natural language understanding, text generation, and conversational AI systems, as well as their potential impact on industries such as healthcare, education, and customer service.\\n\\n5. Ethical, social, and legal implications of LLM: This subtopic will address the ethical, social, and legal considerations surrounding the development and deployment of large language models'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Query Expansion Tool: Develop a tool to expand the subqueries generated by the Topic Breakdown Tool. The tool should generate related keywords, synonyms, and phrases to enhance the search results.\n",
        "\n"
      ],
      "metadata": {
        "id": "QN4R_S2ecvMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query Expansion Tool\n",
        "\n",
        "query_expansion_sys = \"You are an research assistant doing a research on AI and Machine Learning.\"\n",
        "query_expansion_user = \"Expand each subtopic {subtopics} and generate five keywords, synonyms and phrases following this format: {subtopics}\\n [keywords]: []\"\n",
        "def query_expansion(subtopics):\n",
        "  response = get_response(\n",
        "      model=model,\n",
        "      sys_prompt=query_expansion_sys,\n",
        "      user_prompt=f\"{query_expansion_user.format(subtopics=subtopics)}\"\n",
        "  )\n",
        "\n",
        "  expanded_queries = response.choices[0].message.content\n",
        "  return expanded_queries"
      ],
      "metadata": {
        "id": "i3kQlx1tcUt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query_expansion(\"\"\" 1. Development and analysis of language modeling techniques in LLM: This subtopic will focus on the exploration of various language modeling methods, their applications, and comparative analysis to improve the efficiency and effectiveness of language generation in LLM.\n",
        "# 2. Advancements in LLM training strategies: This subtopic will delve into the latest strategies for training large language models, including data selection, preprocessing, and optimization techniques, with a focus on reducing training time and improving model performance.\n",
        "# 3. Evaluation and benchmarking of LLM performance: This subtopic will focus on the development and implementation of suitable evaluation metrics and benchmark datasets to assess the performance of large language models in various aspects such as fluency, accuracy, and generalization.\n",
        "# 4. Exploring applications of LLM in real-world scenarios: This subtopic will examine the practical applications of large language models in areas like natural language understanding, text generation, and conversational AI systems, as well as their potential impact on industries such as healthcare, education, and customer service.\n",
        "# 5. Ethical, social, and legal implications of LLM: This subtopic will address the ethical, social, and legal considerations surrounding the development and deployment of large language models\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "PP3nhctOCFB-",
        "outputId": "10305aff-a43e-4d43-f923-db8d92a691b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 1. Language Modeling Methods: Neural Networks, Transformers, Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), Generative Adversarial Networks (GAN), Transfer Learning, Fine-tuning, BERT, GPT, T5, Language Model Perplexity\\n2. LLM Training Strategies: Data Augmentation, Transfer Learning, Data Parallelism, Gradient Checkpointing, Mixed Precision Training, Batch Normalization, Learning Rate Scheduling, Federated Learning, Meta-Learning\\n3. Evaluation Metrics for LLM: Perplexity, BLEU, ROUGE, METEOR, BERTScore, Automatic Speech Recognition (ASR), Machine Translation (MT) Evaluation metrics, Human Evaluation\\n4. Real-world Applications of LLM: Chatbots, Virtual Assistants, Voice Assistants, Natural Language Understanding, Text Summarization, Sentiment Analysis, Machine Translation, Question Answering, Text Generation for Creative Writing, Personalized Content Generation\\n5. Ethical, Social, and Legal Implications of LL'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. Search Tool: Create a wrapper around the You API or Brave Search API, Serper.dev. Please note that the free tier is 1000 queries/month. Consider creating a mock while developing, and switch to actually call the You API once the agent is more stable. Additionally, consider caching the search results.\n"
      ],
      "metadata": {
        "id": "iZeSJlolcxfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cache = {}"
      ],
      "metadata": {
        "id": "8Qk851U-rWwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search Tool\n",
        "import requests\n",
        "\n",
        "you_api_key = userdata.get('youapi')\n",
        "\n",
        "def get_ai_snippets_for_query(query):\n",
        "    headers = {\"X-API-Key\": you_api_key}\n",
        "    params = {\"query\": query}\n",
        "    response = requests.get(\n",
        "        f\"https://api.ydc-index.io/search\",\n",
        "        params=params,\n",
        "        headers=headers,\n",
        "    ).json()\n",
        "    cache[query] = response['hits']\n",
        "    return response['hits']"
      ],
      "metadata": {
        "id": "oj2WEiIVcbCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ai_snippets_for_query(\"1. Language Modeling Methods: Neural Networks, Transformers, Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), Generative Adversarial Networks (GAN), Transfer Learning, Fine-tuning, BERT, GPT, T5, Language Model Perplexity\\n2. LLM Training Strategies: Data Augmentation, Transfer Learning, Data Parallelism, Gradient Checkpointing, Mixed Precision Training, Batch Normalization, Learning Rate Scheduling, Federated Learning, Meta-Learning\\n3. Evaluation Metrics for LLM: Perplexity, BLEU, ROUGE, METEOR, BERTScore, Automatic Speech Recognition (ASR), Machine Translation (MT) Evaluation metrics, Human Evaluation\\n4. Real-world Applications of LLM: Chatbots, Virtual Assistants, Voice Assistants, Natural Language Understanding, Text Summarization, Sentiment Analysis, Machine Translation, Question Answering, Text Generation for Creative Writing, Personalized Content Generation\\n5. Ethical, Social, and Legal Implications of LL\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNPShw98EjAr",
        "outputId": "b3b3c42c-7159-4111-c745-f798b48a661e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'description': 'A large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised ...',\n",
              "  'snippets': ['As of June 2024, The Instruction fine tuned variant of the Llama 3 70 billion parameter model is the most powerful open LLM according to the LMSYS Chatbot Arena Leaderboard, being more powerful than GPT-3.5 but not as powerful as GPT-4. As of 2024, the largest and most capable models are all based on the Transformer architecture. Some recent implementations are based on other architectures, such as recurrent neural network variants and Mamba (a state space model).',\n",
              "   'A large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process. The largest and most capable LLMs are artificial neural networks built with a decoder-only transformer-based architecture, enabling efficient processing and generation of large-scale text data.',\n",
              "   'Goldman Sachs suggested in 2023 that generative language AI could increase global GDP by 7% in the next ten years, and could expose to automation 300 million jobs globally. Memorization is an emergent behavior in LLMs in which long strings of text are occasionally output verbatim from training data, contrary to typical behavior of traditional artificial neural nets. Evaluations of controlled LLM output measure the amount memorized from training data (focused on GPT-2-series models) as variously over 1% for exact duplicates or up to about 7%.',\n",
              "   'Google converted its translation service to Neural Machine Translation in 2016. As it was before transformers, it was done by seq2seq deep LSTM networks. At the 2017 NeurIPS conference, Google researchers introduced the transformer architecture in their landmark paper \"Attention Is All You Need\". This paper\\'s goal was to improve upon 2014 seq2seq technology, and was based mainly on the attention mechanism developed by Bahdanau et al. in 2014. The following year in 2018, BERT was introduced and quickly became \"ubiquitous\".',\n",
              "   'In his 2014 book titled The Language Myth: Why Language Is Not An Instinct, British cognitive linguist and digital communication technologist Vyvyan Evans mapped out the role of probabilistic context-free grammar (PCFG) in enabling NLP to model cognitive patterns and generate human like language. The canonical measure of the performance of an LLM is its perplexity on a given text corpus.'],\n",
              "  'title': 'Large language model - Wikipedia',\n",
              "  'url': 'https://en.wikipedia.org/wiki/Large_language_model'},\n",
              " {'description': 'Learn what Large Language Models are and why LLMs are essential. Discover its benefits and how you can use it to create new content and ideas including text, conversations, images, video, and audio.',\n",
              "  'snippets': ['Transformer LLMs are capable of unsupervised training, although a more precise explanation is that transformers perform self-learning. It is through this process that transformers learn to understand basic grammar, languages, and knowledge. Unlike earlier recurrent neural networks (RNN) that sequentially process inputs, transformers process entire sequences in parallel.',\n",
              "   \"Similar to code generation, text generation can complete incomplete sentences, write product documentation or, like Alexa Create, write a short children's story. Transformer-based neural networks are very large. These networks contain multiple nodes and layers.\",\n",
              "   \"LLMs can be used for generative AI (artificial intelligence) to produce content based on input prompts in human language. LLMs are big, very big. They can consider billions of parameters and have many possible uses. Here are some examples: Open AI's GPT-3 model has 175 billion parameters.\",\n",
              "   \"LightOn's Paradigm offers foundation models with claimed capabilities that exceed those of GPT-3. All these LLMs come with APIs that allow developers to create unique generative AI applications.\"],\n",
              "  'title': 'What is LLM? - Large Language Models Explained - AWS',\n",
              "  'url': 'https://aws.amazon.com/what-is/large-language-model/'},\n",
              " {'description': 'Pre-trained language models have achieved striking success in natural language processing (NLP), leading to a paradigm shift from supervised learning …',\n",
              "  'snippets': [],\n",
              "  'title': 'Pre-Trained Language Models and Their Applications - ScienceDirect',\n",
              "  'url': 'https://www.sciencedirect.com/science/article/pii/S2095809922006324'},\n",
              " {'description': 'A large language model (LLM) is a computational system, typically a deep neural network with a large number of tunable parameters (i.e., weights), that implements a mathematical function called a language model. A language model (LM), in its most general form, is a probability distribution ...',\n",
              "  'snippets': ['Moreover, unlike RNNs, many aspects of the transformer architecture are easily parallelizable on specialized hardware, enabling substantial scaling of training and inference processes. At present, nearly all LLMs use transformer architectures, the largest having one trillion or more parameters. LLMs are generative models, which, given a prompt (decomposed into tokens), compute a probability distribution over the model’s vocabulary and probabilistically select the next token to generate.',\n",
              "   'As an example of the scale of LLMs, OpenAI’s GPT-3 model has 96 layers of transformer blocks, each of which contains 96 attention heads, with a total of 175 billion tunable parameters (Brown et al., 2020). More recent models have one trillion or more parameters (Minaee et al., 2024). LLMs are trained on large corpora of text data. A masked training method was used for the early LLM BERT (Devlin et al., 2018): certain tokens in the input text are omitted, and the training objective is to predict these “masked” tokens.',\n",
              "   'To address this problem, versions of RNNs were created with features that enhanced their short-term memory (Hochreiter & Schmidhuber, 1997; Cho et al., 2014). In 2017, researchers at Google proposed a novel type of neural network, called a transformer architecture (Vaswani et al., 2017), that was entirely feedforward (meaning that it had no recurrence) but captured long-range dependencies among sequence tokens via a mechanism called attention.',\n",
              "   'This process can be iterated by appending the generated token to the original prompt and using this new prompt to choose the next token, and so on, to generate new text of any length. LLMs typically have a fixed-length context window for their input, in which the original prompt and added tokens are stored; when the context window is full, a token is dropped from the beginning in order to add a new token at the end. LLMs are built on the transformer architecture, which consists of layers of transformer blocks.'],\n",
              "  'title': 'Large Language Models · Open Encyclopedia of Cognitive Science',\n",
              "  'url': 'https://oecs.mit.edu/pub/zp5n8ivs/release/1'},\n",
              " {'description': 'The language model is modeling the probability of generating natural language sentences or documents. You can use the language model to estimate how natural a sentence or a document is. Also, with the language model, you can generate new sentences or documents · Let’s start with modeling ...',\n",
              "  'snippets': ['A LSTM is one of major recurrent neural net modules. It is designed for remembering the long-term memory, so that it should be able to consider relationships of distant words, such that a word at beginning of sentence and it at the end. We also use Dropout before both LSTMs and linear transformations.',\n",
              "   'Let’s see the perplexity on the test split. Trainer’s extension can be used as just a normal function outside of Trainer.',\n",
              "   'To learn the RNN language model, we only need the loss (cross entropy) in the Classifier because we calculate the perplexity instead of classification accuracy to check the performance of the model. So, we turn off computing the accuracy by giving False to model.compute_accuracy attribute. Prepare an optimizer. Here, we use GradientClipping to prevent gradient explosion.',\n",
              "   'Recurrent Neural Net Language Model (RNNLM) is a type of neural net language models which contains the RNNs in the network.'],\n",
              "  'title': 'RNN Language Models — Chainer 7.8.1 documentation',\n",
              "  'url': 'https://docs.chainer.org/en/stable/examples/ptb.html'},\n",
              " {'description': 'Language models have become a fundamental component of natural language processing (NLP) and have revolutionized various tasks, including text generation, machine translation, and sentiment analysis…',\n",
              "  'snippets': ['Language models have become a fundamental component of natural language processing (NLP) and have revolutionized various tasks, including…',\n",
              "   'Gated Recurrent Units (GRUs) are a simplified version of LSTMs that also address the vanishing gradient problem. GRUs use update and reset gates to control the flow of information through the model. Their simpler architecture makes them computationally efficient while maintaining competitive performance. Here’s an example of a GRU-based language model using PyTorch: ... The Generative Pre-trained Transformer (GPT) introduced a breakthrough in language generation tasks.',\n",
              "   'Language models have become a fundamental component of natural language processing (NLP) and have revolutionized various tasks, including text generation, machine translation, and sentiment analysis. In this blog post, we will explore and compare some popular language model architectures: RNN, LSTM, GRU, GPT, and BERT. We will delve into their unique characteristics, applications, and present code snippets showcasing their implementations. ... Recurrent Neural Networks (RNNs) are a class of neural networks well-suited for sequential data processing.',\n",
              "   'It utilizes a stack of self-attention layers to model the relationships between words. Below is an example of using Hugging Face’s Transformers library to generate text with GPT: 5. Bidirectional Encoder Representations from Transformers (BERT):'],\n",
              "  'title': 'Unveiling Language Model Architectures: RNN, LSTM, GRU, GPT, and BERT | by Pradyumna Karkhane | Medium',\n",
              "  'url': 'https://medium.com/@kpradyumna/unveiling-language-model-architectures-rnn-lstm-gru-gpt-and-bert-c9efdf4eb8cc'},\n",
              " {'description': 'Well,In this article, we are going to understand Recurrent Neural Network and Long Short Term Memory. We will go through the basics and how it is working.So lets first understand it. RNN stands for…',\n",
              "  'snippets': ['Well,In this article, we are going to understand Recurrent Neural Network and Long Short Term Memory. We will go through the basics and…',\n",
              "   'So, instead of just normalizing the inputs to the network, we normalize the inputs to each hidden layer within the network. Thanks for reading! I am going to be writing more Deep Learning articles in the future too. Follow me up to be informed about them. And I am also a freelancer,If there is some freelancing work on data-related projects feel free to reach out over Linkedin.Nothing beats working on real projects! ... Analytics Vidhya is a community of Generative AI and Data Science professionals.',\n",
              "   'Vanishing Gradient: This issue occurs when the values of a gradient are too small and the model stops learning or takes way too long because of that. This can be solved using following methods: ... 3. LSTM (Long Short-Term Memory) Best way to solve the vanishing gradient issue is the use of LSTM (Long Short-Term Memory).',\n",
              "   'As we discussed RNN are not able memorize data for long time and begins to forget its previous inputs. To overcome this problem of vanishing and exploding gradient LSTM is used. They are used as solution for short term memory learning. Also in RNN when a new information is added RNN completely modifies the existing information.'],\n",
              "  'title': 'Understanding Recurrent Neural Network (RNN) and Long Short Term Memory(LSTM) | by Vijay Choubey | Analytics Vidhya | Medium',\n",
              "  'url': 'https://medium.com/analytics-vidhya/undestanding-recurrent-neural-network-rnn-and-long-short-term-memory-lstm-30bc1221e80d'},\n",
              " {'description': 'Recurrent Neural Networks (RNNs) are at the heart of many deep learning breakthroughs. What are RNN and LSTM networks and how do they all work?',\n",
              "  'snippets': ['A usual RNN has a short-term memory. In combination with an LSTM they also have a long-term memory (more on that later). Another good way to illustrate the concept of a recurrent neural network’s memory is to explain it with an example: Imagine you have a normal feed-forward neural network and give it the word “neuron” as an input and it processes the word character by character.',\n",
              "   'Vanishing gradients: These occur when the values of a gradient are too small and the model stops learning or takes way too long as a result. Fortunately, it was solved through the concept of LSTM by Sepp Hochreiter and Juergen Schmidhuber. Complex training process: Because RNNs process data sequentially, this can result in a tedious training process.',\n",
              "   'Below is an illustration of an RNN with its three gates: The gates in an LSTM are analog in the form of sigmoids, meaning they range from zero to one. The fact that they are analog enables them to do backpropagation. The problematic issue of vanishing gradients is solved through LSTM because it keeps the gradients steep enough, which keeps the training relatively short and the accuracy high.',\n",
              "   'One-to-many RNNs have one input and several outputs. This enables image captioning or music generation capabilities, as it uses a single input (like a keyword) to generate multiple outputs (like a sentence).'],\n",
              "  'title': 'What Are Recurrent Neural Networks (RNNs)? | Built In',\n",
              "  'url': 'https://builtin.com/data-science/recurrent-neural-networks-and-lstm'},\n",
              " {'description': 'In this blog post, we will explore the process of training and deploying LLMs.',\n",
              "  'snippets': ['Large Language Models (LLMs) have revolutionized the field of natural language processing by exhibiting exceptional performance in various language-related tasks. These models, such as OpenAI’s…',\n",
              "   'The development of large language models can be traced back to significant advancements in deep learning, specifically in the field of recurrent neural networks (RNNs) and later the introduction of Transformer architectures. Before LLMs, traditional language models struggled to capture long-range dependencies and lacked the ability to generate coherent and contextually relevant text. In 2015, researchers introduced the concept of recurrent neural networks with long short-term memory (LSTM) units, which enabled better modeling of sequential data.',\n",
              "   'Model Architecture Selection: Choosing an appropriate model architecture is crucial. Popular choices include Transformer-based architectures like GPT, BERT, or T5.',\n",
              "   'In addition to the Hugging Face Transformers library, there are other software platforms that offer pre-trained LLMs and APIs for easy integration. OpenAI’s GPT-3 and Microsoft’s Turing-NLG are examples of such platforms. They provide pre-trained models that can be accessed via APIs, allowing developers to incorporate advanced language generation and understanding capabilities into their applications without the need for extensive training or infrastructure setup.'],\n",
              "  'title': 'Training and Deploying Large Language Models (LLMs) with Advanced Techniques | by Jesús Cantú | LatinXinAI | Medium',\n",
              "  'url': 'https://medium.com/latinxinai/training-and-deploying-large-language-models-llms-with-advanced-techniques-a81cbf77c871'},\n",
              " {'description': 'Perplexity is a useful metric to evaluate models in Natural Language Processing (NLP). This article will cover the two ways in which it is normally defined and the intuitions behind them. A language…',\n",
              "  'snippets': ['Evaluating language models using the weighted branching factor',\n",
              "   'Perplexity as the normalised inverse probability of the test set 3.1 Probability of the test set 3.2 Normalising 3.3 Bringing it all together'],\n",
              "  'title': 'Perplexity in Language Models. Evaluating language models using the… | by Chiara Campagnola | Towards Data Science',\n",
              "  'url': 'https://towardsdatascience.com/perplexity-in-language-models-87a196019a94'}]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "4. Critique Tool: Create a tool that critiques the summary, and offers suggestions of how to improve and potentially other relevant topics to search for.\n"
      ],
      "metadata": {
        "id": "8rJN51GsczBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Critique Tool\n",
        "\n",
        "critqiue_sys = \"You are a professor in AI and Machine Learning, who is reviewing a summary of a research paper.\"\n",
        "critqiue_user = \"Please critique the following summary and offer suggestions of how to improve and potentially other relevant topics to search for: {summary}.\"\n",
        "\n",
        "def critique(summary):\n",
        "  response = get_response(\n",
        "      model=model,\n",
        "      sys_prompt=critqiue_sys,\n",
        "      user_prompt=f\"{critqiue_user.format(summary=summary)}\"\n",
        "  )\n",
        "\n",
        "  critique = response.choices[0].message.content\n",
        "  return critique\n"
      ],
      "metadata": {
        "id": "V2U2Ztm0c0ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(cache.values())[0]\n",
        "critique(\"\"\"The search results indicate that Large Language Models (LLMs) are a type of computational model designed for natural language processing tasks such as language generation. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process. The largest and most capable LLMs are artificial neural networks built with a decoder-only transformer-based architecture, enabling efficient processing and generation of large-scale text data. These models are capable of unsupervised training, and are often used for generative AI to produce content based on input prompts in human language. Notable examples include OpenAI's GPT-3 model and LightOn's Paradigm. Perplexity is a common metric used to evaluate the performance of LLMs.\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "H_2FZsRAFZ7b",
        "outputId": "f4360807-5060-48fd-857c-c8bccdcff63d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The summary provides a decent overview of Large Language Models (LLMs) and their role in natural language processing. However, there are a few areas where it could be improved and expanded:\\n\\n1. **Context and Background**: Although the summary briefly mentions the purpose of LLMs, it would be beneficial to provide more context about why LLMs were developed and what challenges they aim to address in the field of NLP.\\n\\n2. **Training Process**: While the summary mentions that LLMs learn statistical relationships from large amounts of text, it would be helpful to delve deeper into the specifics of the training process, such as the types of data used, the preprocessing steps, and the optimization techniques employed.\\n\\n3. **Architecture Details**: The summary mentions that LLMs are based on decoder-only transformer architectures, but it does not provide much detail about the architecture itself. You might want to explain the key components of the transformer model and how they contribute to the efficiency of LLMs.\\n\\n4. **Unsupervised Learning**: The summary states that LLMs are capable of unsupervised training, but it would be interesting to explore the implications of this further, such as the types of'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "5. Summarizer Tool (optional): Create a tool that takes some input and summarizes its content using an LLM.\n"
      ],
      "metadata": {
        "id": "qKTF4ELycz-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarizer Tool\n",
        "summarizer_sys = \"You are a research assistant doing a research on AI and Machine Learning..\"\n",
        "summarizer_user = \"Please summarize the search results in one paragraph: {search_results}.\"\n",
        "\n",
        "def summarize(search_results):\n",
        "  response = get_response(\n",
        "      model=model,\n",
        "      sys_prompt=summarizer_sys,\n",
        "      user_prompt=f\"{summarizer_user.format(search_results=search_results)}\"\n",
        "  )\n",
        "\n",
        "  summary = response.choices[0].message.content\n",
        "  return summary\n"
      ],
      "metadata": {
        "id": "RquhpzDHc2zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary optimization tool\n",
        "summary_optim_sys = \"You are an research assistant doing a research on AI and Machine Learning.\"\n",
        "summary_optim_user = \"Improve the summary based on the suggestions. summary: {summary} suggestions: {suggestions}.\"\n",
        "\n",
        "def improve_summary(summary, suggestions):\n",
        "  response = get_response(\n",
        "      model=model,\n",
        "      sys_prompt=summary_optim_sys,\n",
        "      user_prompt=f\"{summary_optim_user.format(summary=summary, suggestions=suggestions)}\"\n",
        "  )\n",
        "  improved_summary = response.choices[0].message.content\n",
        "  return improved_summary\n"
      ],
      "metadata": {
        "id": "QlPpdGqCLylB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(list(cache.values())[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "cUbtRwTZHZAo",
        "outputId": "c02ff466-f9e8-4593-d458-43e3055abd68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" As of 2024, Large Language Models (LLMs) are computational models designed for natural language processing tasks such as language generation. These models, such as OpenAI’s GPT-3 and Google's Transformer-based models, acquire their abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process. The largest and most capable LLMs are artificial neural networks built with a decoder-only transformer-based architecture, enabling efficient processing and generation of large-scale text data. These models are capable of unsupervised training, and are generative models that can consider billions of parameters and have various applications, including text generation, machine translation, and sentiment analysis. Pre-trained LLMs have achieved striking success in natural language processing (NLP), leading to a paradigm shift from supervised learning. The most powerful open LLM, as of June 2024, is The Instruction fine-tuned variant of the Llama 3 70 billion parameter model, which is more powerful than GPT-3.5 but not as powerful as GPT-4.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Workflow (30 points)\n",
        "Implement an agent workflow that uses all of these tools. In the agent workflow, the agent should be provided with all the tools and it should decide which tool to use. For the individual tool implementations, if you use a call to an LLM you do not need to provide any tools.\n",
        "\n",
        "Sample Agent Workflow:\n",
        "1. The agent receives a research topic from the user.\n",
        "2. It uses the Topic Breakdown Tool to generate subtopics or subqueries.\n",
        "3. The Query Expansion Tool expands the subqueries with related keywords and phrases.\n",
        "4. The Search Tool uses the expanded queries and subqueries to gather relevant information from various sources.\n",
        "5. The agent generates the summary incorporating the search results. (optional)\n",
        "6. The agent critiques the summary, and improves the results. (optional)\n",
        "7. The agent presents the final summary to the user.\n",
        "\n",
        "The sample workflow is the minimum implementation requirement. Feel free to add more tools, add loops in the workflow, etc."
      ],
      "metadata": {
        "id": "IGanbUN2cmbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def research_agent():\n",
        "  print(\"Welcome to your personal research agent!\")\n",
        "  input_topic = input(\"Please enter a research topic related to AI and machine learning: \")\n",
        "\n",
        "  subtopics = topic_breakdown(input_topic)\n",
        "  print(\"\\n 1. Subtopics that are generated by the Topic Breakdown Tool: \\n\")\n",
        "  print(\"====\" * 10)\n",
        "  print(subtopics)\n",
        "  print(\"\\n\")\n",
        "\n",
        "  expanded_queries = query_expansion(subtopics)\n",
        "  print(\"\\n 2. Expanded queries that are generated by the Query Expansion Tool: \\n\")\n",
        "  print(\"====\" * 10)\n",
        "  print(expanded_queries)\n",
        "  print(\"\\n\")\n",
        "\n",
        "  search_results = get_ai_snippets_for_query(expanded_queries)\n",
        "  print(\"\\n 3. Search results that are generated by the Search Tool: \\n\")\n",
        "  print(\"====\" * 10)\n",
        "  for result in search_results:\n",
        "    for key, value in result.items():\n",
        "      print(f\"{key}: {value}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  summary = summarize(search_results)\n",
        "  print(\"\\n 4. Summary that is generated by the Summarizer Tool: \\n\")\n",
        "  print(\"====\" * 10)\n",
        "  print(summary)\n",
        "  print(\"\\n\")\n",
        "\n",
        "  critique_res = critique(summary)\n",
        "  print(\"\\n 5. Critique that is generated by the Critique Tool: \\n\")\n",
        "  print(\"====\" * 10)\n",
        "  print(critique_res)\n",
        "  print(\"\\n\")\n",
        "\n",
        "  improve_summary_res = improve_summary(summary, critique_res)\n",
        "  print(\"\\n 6. Improved summary that is generated by the Summary Optimization Tool: \\n\")\n",
        "  print(\"====\" * 10)\n",
        "  print(improve_summary_res)\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"Thank you for using your personal research agent!\")"
      ],
      "metadata": {
        "id": "hr_oZkLcdD44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "research_agent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On8sc9DgJBoP",
        "outputId": "c3317c0c-e1ef-4e33-ea31-8e4aacb1738f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to your personal research agent!\n",
            "Please enter a research topic related to AI and machine learning: computer vision\n",
            "\n",
            " 1. Subtopics that are generated by the Topic Breakdown Tool: \n",
            "\n",
            "========================================\n",
            " 1. Deep Learning Algorithms for Object Detection in Computer Vision: Analyzing the effectiveness and efficiency of popular deep learning models such as YOLO, Faster R-CNN, and SSD for real-time object detection and recognition.\n",
            "\n",
            "2. Computer Vision in Autonomous Vehicles: Investigating the advancements and challenges in using computer vision for self-driving cars, including obstacle detection, lane tracking, and traffic sign recognition.\n",
            "\n",
            "3. Facial Recognition Systems: Evaluating the accuracy, privacy concerns, and ethical implications of facial recognition technology in various applications, such as security systems, social media platforms, and law enforcement.\n",
            "\n",
            "4. GANs (Generative Adversarial Networks) in Computer Vision: Exploring the use of GANs for generating high-quality images, synthetic data, and semantic segmentation, with a focus on applications in medical imaging and video analysis.\n",
            "\n",
            "5. 3D Computer Vision: Studying the techniques for depth estimation, 3D object reconstruction, and motion analysis from 2D images or video sequences, as well as the applications and challenges in augmented reality and robotics.\n",
            "\n",
            "\n",
            "\n",
            " 2. Expanded queries that are generated by the Query Expansion Tool: \n",
            "\n",
            "========================================\n",
            " 1. Deep Learning Object Detection Algorithms (synonyms: CNN-based object detection, real-time object recognition, convolutional neural networks)\n",
            "   - Other algorithms: RetinaNet, EfficientDet, Mask R-CNN.\n",
            "   - Related topics: Image classification, Transfer learning.\n",
            "\n",
            "2. Computer Vision in Autonomous Driving (synonyms: Self-driving car technology, ADAS, advanced driver-assistance systems)\n",
            "   - Other technologies: Lidar, radar, ultrasound.\n",
            "   - Challenges: Poor visibility, dynamic environments, adversarial attacks.\n",
            "\n",
            "3. Facial Recognition Systems (synonyms: Biometric recognition, face identification, face verification)\n",
            "   - Applications: Access control, surveillance, forensics.\n",
            "   - Privacy concerns: Data breaches, mass surveillance, bias in algorithms.\n",
            "\n",
            "4. GANs in Computer Vision (synonyms: Generative modeling, deep fakes, image synthesis)\n",
            "   - Applications: Super-resolution, style transfer, medical imaging.\n",
            "   - Challenges: Mode collapse, training instability, quality of generated images.\n",
            "\n",
            "5. 3D Computer Vision (synonyms: Stereo vision, depth perception, 3D reconstruction)\n",
            "   - Techniques: Structured light, time-of-flight, stereo matching.\n",
            "   - Applications: Virtual reality, robotics, autonomous mapping.\n",
            "   - Challenges: occlusion, textureless surfaces, scale ambiguity.\n",
            "\n",
            "\n",
            "\n",
            " 3. Search results that are generated by the Search Tool: \n",
            "\n",
            "========================================\n",
            "description: Complete overview of Object Detection. Introduction to the most popular Computer Vision and Deep Learning Object Detection Algorithms.\n",
            "snippets: ['Mask R-CNN Example with image segmentation and image object detection · SqueezeDet is the name of a deep neural network for computer vision that was released in 2016. It was specifically developed for autonomous driving, where it performs object detection using computer vision techniques. Like YOLO, it is a single-shot detector algorithm. In SqueezeDet, convolutional layers are used not only to extract feature maps but also as the output layer to compute bounding boxes and class probabilities.', 'Read more to learn more about how Viso Suite can implement product detection technology in your business. ... Object detection methods are increasingly important for computer vision applications in any industry. If you enjoyed reading this article, I would suggest reading: An Introduction to MLOps – Methods To Deliver Machine Learning · Explore the fast Segment Anything Model (SAM) that can identify objects without training · Read more about Convolutional Neural Networks (CNNs)', 'Such hardware allows applying computer vision for object detection and tracking in near real-time environments. Hence, rapid development in deep convolutional neural networks (CNN) and GPU’s enhanced computing power are the main drivers behind the great advancement of computer vision-based object detection.', 'On the MS COCO dataset and based on the Average Precision (AP), the best real-time object detection algorithm is YOLOv7, followed by Vision Transformer (ViT) such as Swin and DualSwin, PP-YOLOE, YOLOR, YOLOv4, and EfficientDet. Real-time Object Detection on COCO Benchmark: The state-of-the-art by Average Precision (AP) Also, on the MS COCO dataset, an important benchmark metric is inference time (ms/Frame, lower is better) or Frames per Second (FPS, higher is better). The rapid advances in computer vision technology are very visible when looking at inference time comparisons.']\n",
            "title: Object Detection: The Definitive 2025 Guide - viso.ai\n",
            "url: https://viso.ai/deep-learning/object-detection/\n",
            "description: Object detection is an essential area of computer vision and artificial intelligence, which lets computer programs \"see\" their environment by recognizing things in pictures or videos. The advancements in deep learning have resulted in exceptional precision rates for object detection.\n",
            "snippets: ['Discover the best object detection models for 2024, perfect for computer vision and machine learning applications.', 'Note: RetinaNet also comes with Apache License 2.0, which means you can use this model for free for personal and commercial projects. ... DagsHub helps you easily curate and annotate your vision, audio, and document data with a single platform. Book a Demo ... In 2015, a team of Microsoft researchers developed and unveiled the R-CNN, focusing on cutting the model training time. The R-CNN, the previous version, processes the neural network features independently, but this faster version computes the neural network as a chunk at once.', '2) Deep learning algorithms with two stages, including examples such as various R-CNN models faster object separation from the background with faster speeds and higher accuracy. 3) Deep learning algorithms with one stage, such as YOLO models, RetinaNet, and SSDs. Compared to the other types, these are much faster approaches but often need more accuracy. Object detection models employ a combination of convolutional layers for feature extraction and other specialized layers, such as region proposal networks (RPN) or anchor-based mechanisms to generate bounding boxes around objects of interest.', \"Therefore, Mask R-CNN combines object detection and instance segmentation, allowing developers to detect objects and precisely understand detected objects' boundaries at the pixel level. Mask R-CNN uses a Feature Pyramid Network (FPN) and the Region of Interest Align (ROIAlign) in the background to make this happen.\"]\n",
            "title: Best Object Detection Models (2024 List)\n",
            "url: https://dagshub.com/blog/best-object-detection-models/\n",
            "description: A technical guide to leading object detection algorithms for computer vision, covering two-stage, one-stage, and transformer-based algorithm\n",
            "snippets: ['RCNN, or Regions with Convolutional Neural Networks, marked the first application of deep learning in the realm of object detection. The central idea behind the algorithm is straightforward: For every image, the RCNN initially employs a selective search algorithm [1] to generate approximately 2000 candidate regions. These regions are resized to a consistent dimension, and their features are subsequently extracted using a Convolutional Neural Network (CNN).', '\"Faster R-CNN: Towards Real Time Object Detection with Region Proposal Networks.\" In Neural Information Processing Systems (pp. 91–99). Lin, T., Dollár, P., Girshick, R., He, K., Hariharan, B., & Belongie, S. (2017). \"Feature Pyramid Networks for Object Detection.\" In Conference on Computer Vision and Pattern Recognition. He, K., Gkioxari, G., Dollár, P., & Girshick, R. (2017). \"Mask R-CNN.\"', \"Secondly, the extraction of 2000 region proposals and computation of CNN features for each region in an image results in a vast quantity of features. This abundance significantly reduces the model's inference speed. On average, it takes approximately 45 seconds per image for prediction, rendering RCNN impractical for utilization on large-scale datasets. In the original RCNN model, each candidate region necessitates separate feature extraction using a Convolutional Neural Network (CNN).\", 'Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A., Kaiser, Ł., & Polosukhin, I. (2017). \"Attention is All You Need.\" In Neural Information Processing Systems. Hu, H., Gu, J., Zhang, Z., Dai, J., & Wei, Y. (2018). \"Relation Networks for Object Detection.\" In Conference on Computer Vision and Pattern Recognition.']\n",
            "title: Leading Object Detection Algorithms in 2023: A Comprehensive Overview | BasicAI's Blog\n",
            "url: https://www.basic.ai/blog-post/object-detection-algorithms-overview\n",
            "description: It can be challenging for beginners to distinguish between different related computer vision tasks. For example, image classification is straight forward, but the differences between object localization and object detection can be confusing, especially when all three tasks may be just as equally ...\n",
            "snippets: ['It can be challenging for beginners to distinguish between different related computer vision tasks. For example, image classification is straight forward, but the differences between object localization and object detection can be confusing, especially when all three tasks may be just as equally referred to as object recognition.', 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, 2016. Mask R-CNN, 2017. You Only Look Once: Unified, Real-Time Object Detection, 2015. YOLO9000: Better, Faster, Stronger, 2016. YOLOv3: An Incremental Improvement, 2018. R-CNN: Regions with Convolutional Neural Network Features, GitHub.', 'A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN, 2017. Object Detection for Dummies Part 3: R-CNN Family, 2017. Object Detection Part 4: Fast Detection Models, 2018. In this post, you discovered a gentle introduction to the problem of object recognition and state-of-the-art deep learning models designed to address it. ... Object recognition is refers to a collection of related tasks for identifying objects in digital photographs. Region-Based Convolutional Neural Networks, or R-CNNs, are a family of techniques for addressing object localization and recognition tasks, designed for model performance.', 'A prior work was proposed to speed up the technique called spatial pyramid pooling networks, or SPPnets, in the 2014 paper “Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition.” This did speed up the extraction of features, but essentially used a type of forward pass caching algorithm. Fast R-CNN is proposed as a single model instead of a pipeline to learn and output regions and classifications directly. The architecture of the model takes the photograph a set of region proposals as input that are passed through a deep convolutional neural network.']\n",
            "title: A Gentle Introduction to Object Recognition With Deep Learning - MachineLearningMastery.com\n",
            "url: https://machinelearningmastery.com/object-recognition-with-deep-learning/\n",
            "description: Object detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class (such as humans, buildings, or cars) in digital images and videos. Well-researched domains of object detection include face detection ...\n",
            "snippets: ['For non-neural approaches, it becomes necessary to first define features using one of the methods below, then using a technique such as support vector machine (SVM) to do the classification. On the other hand, neural techniques are able to do end-to-end object detection without specifically defining features, and are typically based on convolutional neural networks (CNN).', 'To address the challenges caused by the domain gap between training and test data, many unsupervised domain adaptation approaches have been proposed. A simple and straightforward solution for reducing the domain gap is to apply an image-to-image translation approach, such as cycle-GAN. Among other uses, cross-domain object detection is applied in autonomous driving, where models can be trained on a vast amount of video game scenes, since the labels can be generated without manual labor.', 'Object detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class (such as humans, buildings, or cars) in digital images and videos. Well-researched domains of object detection include face detection and pedestrian detection.', 'For example, if there is a traffic sign in the image, with a bounding box drawn by a human (\"ground truth label\"), then a neural network has detected the traffic sign (a true positive) at 0.5 threshold iff it has drawn a bounding box whose IoU with the ground truth is above 0.5.', 'The average precision (AP) of the network for a class of objects is the area under the precision-recall curve as the IoU threshold is varied. The mAP is the average of AP over all classes. Methods for object detection generally fall into either neural network-based or non-neural approaches.']\n",
            "title: Object detection - Wikipedia\n",
            "url: https://en.wikipedia.org/wiki/Object_detection\n",
            "description: Learn about the latest object detection algorithms and their applications with our comprehensive online resource. Visit now .\n",
            "snippets: ['Explore practical solutions, advanced retrieval strategies, and agentic RAG systems to improve context, relevance, and accuracy in AI-driven applications. ... Master MS Excel for data analysis with key formulas, functions, and LookUp tools in this comprehensive course. ... Introduction to Convolutional Neural Networks (... A Practical Implementation of the Faster R-CNN ... Object Detection Algorithms: R-CNN, Fast R-CNN,... ... Computer Vision Tutorial: Implementing Mask R-C...', 'Why do we need Region Based Convolulional Neural Network? Fast R-CNN and Faster R-CNN Building Social Distancting Tool using Faster R-CNN · Single Shot Detector SSD Custom Object Detection on the browser using TensorFlow.js YOLOv1 Other Versions of YOLO (v2 and v3) YOLOv3 YOLOv4 YOLOv5 YOLOv7 RetinaNet ... Introduction to Face Detection Why is Face Alignment Important for Face Recognition?', 'A Practical Implementation of the Faster R-CNN Algorithm for Object Detection (Part 2) A Practical Guide to Object Detection using the Popular YOLO Framework – Part III (with Python codes) Let’s get started! A Simple Way of Solving an Object Detection Task (using Deep Learning) Understanding Region-Based Convolutional Neural Network', 'We first take a pre-trained convolutional neural network. Then, this model is retrained. We train the last layer of the network based on the number of classes that need to be detected. The third step is to get the Region of Interest for each image. We then reshape all these regions so that they can match the CNN input size.']\n",
            "title: A Step-by-Step Introduction to the Basic Object Detection Algorithms (Part 1)\n",
            "url: https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/\n",
            "description: Help | Advanced Search · arXiv is a free distribution service and an open-access archive for nearly 2.4 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and ...\n",
            "snippets: []\n",
            "title: A Survey of Deep Learning-based Object Detection\n",
            "url: https://arxiv.org/pdf/1907.09408\n",
            "description: “Object detection is one of the most exciting and challenging problems in computer vision, and deep learning has emerged as a powerful tool to tackle it.” — Dr.\n",
            "snippets: [\"Here's a simplified example of how you can utilize the EfficientDet model for object detection using a popular deep learning library like TensorFlow. RetinaNet is a deep learning model for object detection that uses a feature pyramid network and a new focal loss function.\", 'Faster R-CNN, an innovative deep learning model, has revolutionized object detection by introducing the concept of Region Proposal Networks (RPNs) for efficient and accurate object localization. This section delves into the architecture, advantages, and challenges of Faster R-CNN, while also providing a sample code snippet for a better understanding. Faster R-CNN, short for Faster Region Convolutional Neural Network, is built upon the R-CNN family of models.', 'Developed as a successor to Faster R-CNN, Mask R-CNN combines object detection and instance segmentation in a single framework, making it a versatile tool for a wide range of computer vision tasks. The architecture of Mask R-CNN builds upon the foundation of Faster R-CNN while introducing additional components to handle instance segmentation. Similar to Faster R-CNN, Mask R-CNN employs a Region Proposal Network (RPN) to generate candidate object regions.', 'The hallmark innovation of Faster R-CNN is the inclusion of Region Proposal Networks (RPNs). RPNs are integrated into the network, allowing it to propose potential regions where objects might exist. These regions are then used as candidate regions for object detection and classification. The RPN is a fully convolutional network that operates on a sliding window of different sizes, generating anchor boxes (predefined bounding box shapes) at each location.']\n",
            "title: Top 10 Object Detection Models in 2023!\n",
            "url: https://www.linkedin.com/pulse/top-10-object-detection-models-2023-jagrat-patel\n",
            "description: Help | Advanced Search · arXiv is a free distribution service and an open-access archive for nearly 2.4 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and ...\n",
            "snippets: []\n",
            "title: Object Detection with Deep Learning: A Review\n",
            "url: http://arxiv.org/pdf/1807.05511\n",
            "description: In this post, I shall explain object detection and various algorithms like Faster R-CNN, YOLO, SSD. We shall start from beginners' level and go till the state-of-the-art in object detection, understanding the intuition, approach and salient features of each method.\n",
            "snippets: ['Object Detection is the backbone of many practical applications of computer vision such as autonomous cars, security and surveillance, and many industrial applications. Hopefully, this post gave you an intuition and understanding behind each of the popular algorithms for object detection. Fast-RCNN, Faster-RCNN, object detection, Single Shot Detector, SSD, YOLO · Tensorflow Tutorial 2: image classifier using convolutional neural network', 'After the rise of deep learning, the obvious idea was to replace HOG based classifiers with a more accurate convolutional neural network based classifier. However, there was one problem. CNNs were too slow and computationally very expensive. It was impossible to run CNNs on so many patches generated by sliding window detector. R-CNN solves this problem by using an object proposal algorithm called Selective Search which reduces the number of bounding boxes that are fed to the classifier to close to 2000 region proposals.', 'This multitask objective is a salient feature of Fast-rcnn as it no longer requires training of the network independently for classification and localization. These two changes reduce the overall training time and increase the accuracy in comparison to SPP net because of the end to end learning of CNN. So, what did Faster RCNN improve? Well, it’s faster. And How does it achieve that? Slowest part in Fast RCNN was Selective Search or Edge boxes. Faster RCNN replaces selective search with a very small convolutional network called Region Proposal Network to generate regions of Interests.', 'There was one more challenge: we need to generate the fixed size of input for the fully connected layers of the CNN so, SPP introduces one more trick. It uses spatial pooling after the last convolutional layer as opposed to traditionally used max-pooling. SPP layer divides a region of any arbitrary size into a constant number of bins and max pool is performed on each of the bins.']\n",
            "title: Zero to Hero: Guide to Object Detection using Deep Learning: Faster R-CNN,YOLO,SSD – CV-Tricks.com\n",
            "url: https://cv-tricks.com/object-detection/faster-r-cnn-yolo-ssd/\n",
            "\n",
            "\n",
            "\n",
            " 4. Summary that is generated by the Summarizer Tool: \n",
            "\n",
            "========================================\n",
            " The search results provide an overview of object detection in computer vision and deep learning, highlighting popular algorithms such as Mask R-CNN, SqueezeDet, YOLO (YOLOv7, YOLOv3, YOLOv4, YOLOv5, YOLOv9000), RetinaNet, and EfficientDet. These algorithms are used for tasks such as autonomous driving, security and surveillance, and industrial applications. The results also discuss the importance of region proposal networks (RPNs) and features like the FPN (Feature Pyramid Network) and ROIAlign (Region of Interest Align) in object detection models like Faster R-CNN and Mask R-CNN. Additionally, the research points out that deep learning-based object detection has significantly improved precision rates in recent years.\n",
            "\n",
            "\n",
            "\n",
            " 5. Critique that is generated by the Critique Tool: \n",
            "\n",
            "========================================\n",
            " The summary provides a good overview of object detection in computer vision and deep learning, focusing on popular algorithms and their applications. However, there are a few areas that could be improved and additional topics that could be addressed for a more comprehensive review:\n",
            "\n",
            "1. Clarify the purpose of the summary: Is it to inform readers about the current state of object detection research, or to evaluate the effectiveness of different algorithms for specific applications?\n",
            "2. Provide more context about the research: What is the motivation behind the paper, and what questions does it aim to answer? What are the key findings, and how do they contribute to the field of object detection?\n",
            "3. Discuss the limitations of the algorithms: While the summary mentions the importance of deep learning-based object detection in improving precision rates, it would be helpful to discuss the challenges and limitations faced by these algorithms, such as computational costs, robustness to variations in lighting and weather conditions, and the difficulty of detecting small or occluded objects.\n",
            "4. Compare and contrast the algorithms: Rather than simply listing the algorithms, it would be helpful to compare and contrast their strengths and weaknesses, and discuss how they differ in terms of accuracy, speed, and computational requirements.\n",
            "5. Discuss recent advancements in object detection: The summary mentions that deep learning-based object detection has significantly improved precision rates in recent years, but it would be helpful to provide more details about the specific advancements that have contributed to this improvement, such as the use of transfer learning, multi-task learning, and attention mechanisms.\n",
            "6. Discuss future directions for research: What are the open challenges and research directions in object detection, and how could future research address these challenges? For example, how could object detection be improved for real-time applications, or for applications in complex environments such as urban scenes or cluttered indoor spaces?\n",
            "7. Incorporate related topics: The summary focuses on object detection, but there are related topics that could be addressed, such as semantic segmentation, instance segmentation, and object tracking. It would be helpful to discuss how these tasks are related to object detection and how they complement each other in various applications.\n",
            "\n",
            "Overall, the summary provides a good starting point for understanding the current state of object detection research, but it could be improved by providing more context, discussing limitations and advancements, comparing and contrasting algorithms, and incorporating related topics.\n",
            "\n",
            "\n",
            "\n",
            " 6. Improved summary that is generated by the Summary Optimization Tool: \n",
            "\n",
            "========================================\n",
            " Title: A Comprehensive Review of Object Detection in Computer Vision and Deep Learning: Popular Algorithms, Applications, and Future Directions\n",
            "\n",
            "Summary: This research provides an in-depth analysis of object detection in computer vision and deep learning, with a focus on popular algorithms such as Mask R-CNN, SqueezeDet, YOLO (YOLOv7, YOLOv3, YOLOv4, YOLOv5, YOLOv9000), RetinaNet, and EfficientDet. These algorithms are widely utilized in various applications including autonomous driving, security and surveillance, and industrial processes. The paper delves into the significance of region proposal networks (RPNs) and features such as the FPN (Feature Pyramid Network) and ROIAlign (Region of Interest Align) in object detection models like Faster R-CNN and Mask R-CNN.\n",
            "\n",
            "Moreover, the research emphasizes the substantial enhancement in precision rates achieved by deep learning-based object detection in recent years. However, the paper also acknowledges the challenges faced by these algorithms, including computational costs, robustness to variations in lighting and weather conditions, and the difficulty of detecting small or occluded objects.\n",
            "\n",
            "To provide a more comprehensive review, the paper could be improved by clarifying its purpose, discussing the motivation and key findings of the research, and comparing and contrasting the strengths and weaknesses of the algorithms. Additionally, the paper could delve into recent advancements in object detection, such as the use of transfer learning, multi-task learning, and attention mechanisms, and discuss future research directions to address open challenges in real-time and complex environments.\n",
            "\n",
            "Furthermore, the paper could incorporate related topics such as semantic segmentation, instance segmentation, and object tracking, and discuss how these tasks are interconnected and complement each other in various applications. Overall, this research offers a valuable insight into the current state of object detection, but could benefit from more context, a comparison of algorithms, and a discussion of related topics and future research directions.\n",
            "\n",
            "\n",
            "Thank you for using your personal research agent!\n"
          ]
        }
      ]
    }
  ]
}